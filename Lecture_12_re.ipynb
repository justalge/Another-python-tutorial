{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 12. re.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFlKI/JE7+E1+XaO5CH0sk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justalge/another_python_tutorial/blob/main/Lecture_12_re.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bQhYGHAbolh"
      },
      "source": [
        "## re: Regular Expressions\n",
        "\n",
        "The term \"regular expression\", sometimes also called regex or regexp, has originated in theoretical computer science. In theoretical computer science, they are used to define a language family with certain characteristics, the so-called regular languages. A finite state machine (FSM), which accepts language defined by a regular expression, exists for every regular expression. You can find an implementation of a [Finite State Machine in Python](https://www.python-course.eu/finite_state_machine.php)\n",
        "\n",
        "Regular Expressions are used in programming languages to filter texts or textstrings. It's possible to check, if a text or a string matches a regular expression. A great thing about regular expressions: The syntax of regular expressions is the same for all programming and script languages, e.g. Python, Perl, Java, SED, AWK and even X#.\n",
        "\n",
        "The first programs which had incorporated the capability to use regular expressions were the Unix tools ed (editor), the stream editor sed and the filter grep ([you SHOULD know this](https://ostechnix.com/the-grep-command-tutorial-with-examples-for-beginners/)).\n",
        "\n",
        "There is another mechanism in operating systems, which shouldn't be mistaken for regular expressions. Wildcards, also known as globbing, look very similar in their syntax to regular expressions. However, the semantics differ considerably. Globbing is known from many command line shells, like the Bourne shell, the Bash shell or even DOS. In Bash e.g. the command \"ls .txt\" lists all files (or even directories) ending with the suffix .txt; in regular expression notation \".txt\" wouldn't make sense, it would have to be written as \".*.txt\"\n",
        "\n",
        "#### Introduction\n",
        "\n",
        "When we introduced the sequential data types, we got to know the \"in\" operator. We check in the following example, if the string \"easily\" is a substring of the string \"Regular expressions easily explained!\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quOyWn0kZmRu",
        "outputId": "6292a2dc-6911-4d26-8813-b7183bd3d4a1"
      },
      "source": [
        "s = \"Regular expressions easily explained!\"\n",
        "\"easily\" in s"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJUtjHbWdaA4"
      },
      "source": [
        "We show step by step with the following diagrams how this matching is performed: We check if the string sub = \"abc\"\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression2.webp)\n",
        "\n",
        "s contained in the string s = \"xaababcbcd\"\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression1_400w.webp)\n",
        "\n",
        "By the way, the string sub = \"abc\" can be seen as a regular expression, just a very simple one.\n",
        "\n",
        "In the first place, we check, if the first positions of the two string match, i.e. s[0] == sub[0]. This is not satisfied in our example. We mark this fact by the colour red:\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression3_400w.webp)\n",
        "\n",
        "Then we check, if s[1:4] == sub. In other words, we have to check at first, if sub[0] is equal to s[1]. This is true and we mark it with the colour green. Then, we have to compare the next positions. s[2] is not equal to sub[1], so we don't have to proceed further with the next position of sub and s:\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression4_400w.webp)\n",
        "\n",
        "Now we have to check if s[2:5] and sub are equal. The first two positions are equal but not the third:\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression5_400w.webp)\n",
        "\n",
        "The following steps should be clear without any explanations:\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression6_400w.webp)\n",
        "\n",
        "Finally, we have a complete match with s[4:7] == sub :\n",
        "\n",
        "![](https://www.python-course.eu/images/regular_expression7_400w.webp)\n",
        "\n",
        "#### Representing Regular Expressions in Python\n",
        "\n",
        "As we have already mentioned in the previous section, we can see the variable \"sub\" from the introduction as a very simple regular expression. If you want to use regular expressions in Python, you have to import the re module, which provides methods and functions to deal with regular expressions.\n",
        "\n",
        "From other languages you might be used to representing regular expressions within Slashes \"/\", e.g. that's the way Perl, SED or AWK deals with them. In Python there is no special notation. Regular expressions are represented as normal strings.\n",
        "\n",
        "But this convenience brings along a small problem: The backslash is a special character used in regular expressions, but is also used as an escape character in strings. This implies that Python would first evaluate every backslash of a string and after this - without the necessary backslashes - it would be used as a regular expression. One way to prevent this could be writing every backslash as \"\\\\\" and this way keep it for the evaluation of the regular expression. This can cause extremely clumsy expressions. So, a regular expression to match the Windows path \"C:\\\\\\\\programs\" corresponds to a string in regular expression notation with four backslashes, i.e. \"C:\\\\\\\\\\\\\\\\programs\".\n",
        "\n",
        "The best way to overcome this problem would be marking regular expressions as raw strings. The solution to our Windows path example looks like this as a raw string:\n",
        "\n",
        "```r\"C:\\\\programs\"```\n",
        "\n",
        "Let's look at another example, which might be quite disturbing for people who are used to wildcards:\n",
        "\n",
        "```r\"^a.*\\.html$\"```\n",
        "\n",
        "The regular expression of our previous example matches all file names (strings) which start with an \"a\" and end with \".html\". We will the structure of the example above in detail explain in the following sections\n",
        "\n",
        "#### Syntax of Regular Expression\n",
        "\n",
        "```r\"cat\"``` is a regular expression, though a very simple one without any metacharacters. Our RE ```r\"cat\"``` matches, for example, the following string: \"A cat and a rat can't be friends.\"\n",
        "\n",
        "Interestingly, the previous example shows already a \"favourite\" example for a mistake, frequently made not only by beginners and novices but also by advanced users of regular expressions. The idea of this example is to match strings containing the word \"cat\". We are successful at this, but unfortunately we are matching a lot of other words as well. If we match \"cats\" in a string that might be still okay, but what about all those words containing this character sequence \"cat\"? We match words like \"education\", \"communicate\", \"falsification\", \"ramifications\", \"cattle\" and many more. This is a case of \"over matching\", i.e. we receive positive results, which are wrong according to the problem we want to solve.\n",
        "\n",
        "If we try to fix the previous RE, so that it doesn't create over matching, we might try the expression ```r\" cat \"```. These blanks prevent the matching of the above mentioned words like \"education\", \"falsification\" and \"ramification\", but we fall prey to another mistake. What about the string \"The cat, called Oscar, climbed on the roof.\"? The problem is that we don't expect a comma but only a blank surrounding the word \"cat\".\n",
        "\n",
        "Before we go on with the description of the syntax of regular expressions, we want to explain how to use them in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rFDTtSmdWTD",
        "outputId": "25080250-d517-4a56-dd20-a7dfc453dc0b"
      },
      "source": [
        "import re\n",
        "x = re.search(\"cat\", \"A cat and a rat can't be friends.\")\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(2, 5), match='cat'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_gCZ5kHiQwl",
        "outputId": "b60fc5e1-0722-4b3d-d290-b88d83ba5459"
      },
      "source": [
        "x = re.search(\"cow\", \"A cat and a rat can't be friends.\")\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4CEef4iwhF"
      },
      "source": [
        "We used the method search from the re module. **This is most probably the most important and the most often used method of this module**. re.search(expr,s) checks a string s for an occurrence of a substring which matches the regular expression expr. The first substring (from left), which satisfies this condition will be returned. If a match has been possible, we get a so-called match object as a result, otherwise the value will be None. This method is already enough to use regular expressions in a basic way in Python programs. We can use it in conditional statements: If a regular expression matches, we get an SRE object returned, which is taken as a True value, and None, which is the return value if it doesn't match, is taken as False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4QCpboHidEK",
        "outputId": "964bfb75-2a60-4fd9-caf0-4dec4b421bd8"
      },
      "source": [
        "if re.search(\"cat\", \"A cat and a rat can't be friends.\"):\n",
        "    print(\"Some kind of cat has been found :-)\")\n",
        "else:\n",
        "    print(\"No cat has been found :-)\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some kind of cat has been found :-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPSt361bi4f6",
        "outputId": "9c470d04-c83b-4e4a-dd93-b3b4a7638348"
      },
      "source": [
        "if re.search(\"cow\", \"A cat and a rat can't be friends.\"):\n",
        "     print(\"Cats and Rats and a cow.\")\n",
        "else:\n",
        "     print(\"No cow around.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No cow around.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp3N3vFfjCtX"
      },
      "source": [
        "#### Any Character\n",
        "\n",
        "Let's assume that we have not been interested in the previous example to recognize the word cat, but all three letter words, which end with \"at\". The syntax of regular expressions supplies a metacharacter \".\", which is used like a placeholder for \"any character\". The regular expression of our example can be written like this: r\" .at \" This RE matches three letter words, isolated by blanks, which end in \"at\". Now we get words like \"rat\", \"cat\", \"bat\", \"eat\", \"sat\" and many others.\n",
        "\n",
        "But what if the text contains \"words\" like \"@at\" or \"3at\"? These words match as well, meaning we have caused over matching again. We will learn a solution in the following section.\n",
        "\n",
        "#### Character Classes\n",
        "\n",
        "Square brackets, \"[\" and \"]\", are used to include a character class. [xyz] means e.g. either an \"x\", an \"y\" or a \"z\". Let's look at a more practical example:\n",
        "\n",
        "```r\"M[ae][iy]er\"```\n",
        "\n",
        "This is a regular expression, which matches a surname which is quite common in German. A name with the same pronunciation and four different spellings: Maier, Mayer, Meier, Meyer A finite state automata to recognize this expression can be build like this:\n",
        "\n",
        "![](https://www.python-course.eu/images/finite_state_machine_mayer_400w.webp)\n",
        "\n",
        "The graph of the finite state machine (FSM) is simplified to keep the design easy. There should be an arrow in the start node pointing back on its own, i.e. if a character other than an upper case \"M\" has been processed, the machine should stay in the start condition. Furthermore, there should be an arrow pointing back from all nodes except the final nodes (the green ones) to the start node, unless the expected letter has been processed. E.g. if the machine is in state Ma, after having processed a \"M\" and an \"a\", the machine has to go back to state \"Start\", if any character except \"i\" or \"y\" can be read. Those who have problems with this FSM, shouldn't worry, since it is not a prerequisite for the rest of the chapter.\n",
        "\n",
        "Instead of a choice between two characters, we often need a choice between larger character classes. We might need e.g. a class of letters between \"a\" and \"e\" or between \"0\" and \"5\". To manage such character classes, the syntax of regular expressions supplies a metacharacter \"-\". [a-e] a simplified writing for [abcde] or [0-5] denotes [012345].\n",
        "\n",
        "The advantage is obvious and even more impressive, if we have to coin expressions like \"any uppercase letter\" into regular expressions. So instead of [ABCDEFGHIJKLMNOPQRSTUVWXYZ] we can write [A-Z]. If this is not convincing: Write an expression for the character class \"any lower case or uppercase letter\" [A-Za-z]\n",
        "\n",
        "There is something more about the dash, we used to mark the begin and the end of a character class. The dash has only a special meaning if it is used within square brackets and in this case only if it isn't positioned directly after an opening or immediately in front of a closing bracket. So the expression [-az] is only the choice between the three characters \"-\", \"a\" and \"z\", but no other characters. The same is true for [az-].\n",
        "\n",
        "The only other special character inside square brackets (character class choice) is the **caret \"^\"**. If it is used directly after an opening sqare bracket, it negates the choice. [^0-9] denotes the choice \"any character but a digit\". The position of the caret within the square brackets is crucial. If it is not positioned as the first character following the opening square bracket, it has no special meaning. [^abc] means anything but an \"a\", \"b\" or \"c\" [a^bc] means an \"a\", \"b\", \"c\" or a \"^\"\n",
        "\n",
        "##### Example:\n",
        "\n",
        "We have a phone list of the Simpsons, yes, the famous Simpsons from the American animated TV series. There are some people with the surname Neu. We are looking for a Neu, but we don't know the first name, we just know that it starts with a J. Let's write a Python script, which finds all the lines of the phone book, which contain a person with the described surname and a first name starting with J.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUSpeMkTi9I1",
        "outputId": "5fa13226-2d62-472b-b301-17605409bfe5"
      },
      "source": [
        "import re\n",
        "\n",
        "from urllib.request import urlopen\n",
        "with urlopen('https://www.python-course.eu/simpsons_phone_book.txt') as fh:\n",
        "    for line in fh:\n",
        "        # line is a byte string so we transform it to utf-8:\n",
        "        line = line.decode('utf-8').rstrip() \n",
        "        if re.search(r\"J.*Neu\",line):\n",
        "            print(line)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack Neu 555-7666\n",
            "Jeb Neu 555-5543\n",
            "Jennifer Neu 555-3652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tL8HqdqkVo"
      },
      "source": [
        "#### Predefined Character Classes\n",
        "\n",
        "You might have realized that it can be quite cumbersome to construe certain character classes. A good example is the character class, which describes a valid word character. These are all lower case and uppercase characters plus all the digits and the underscore, corresponding to the following regular expression: r\"[a-zA-Z0-9_]\"\n",
        "\n",
        "Predefined character classes:\n",
        "\n",
        "* `\\d` - Matches any decimal digit; equivalent to the set [0-9]\n",
        "* `\\D` - The complement of \\d. It matches any non-digit character; equivalent to the set [^0-9]\n",
        "* `\\s` - Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v]\n",
        "* `\\S` - The complement of \\s. It matches any non-whitespace character; equiv. to [^ \\t\\n\\r\\f\\v]\n",
        "* `\\w` - Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]. With LOCALE, it will match the set [a-zA-Z0-9_] plus characters defined as letters for the current locale\n",
        "* `\\W` - Matches the complement of \\w\n",
        "* `\\b` - Matches the empty string, but only at the start or end of a word\n",
        "* `\\B` - Matches the empty string, but not at the start or end of a word\n",
        "* `\\\\` - Matches a literal backslash\n",
        "\n",
        "#### Word boundaries\n",
        "\n",
        "The \\b and \\B of the previous overview of special sequences, is often not properly understood or even misunderstood especially by novices. While the other sequences match characters, - e.g. \\w matches characters like \"a\", \"b\", \"m\", \"3\" and so on, - \\b and \\B don't match a character. They match empty strings depending on their neighbourhood, i.e. what kind of a character the predecessor and the successor is. So \\b matches any empty string between a \\W and a \\w character and also between a \\w and a \\W character. \\B is the complement, i.e empty strings between \\W and \\W or empty strings between \\w and \\w.\n",
        "\n",
        "#### Matching Beginning and End\n",
        "\n",
        "But what if we want to match a regular expression at the beginning of a string and only at the beginning?\n",
        "\n",
        "The re module of Python provides two functions to match regular expressions. We have met already one of them, i.e. search(). The other has in our opinion a misleading name: match() Misleading, because match(re_str, s) checks for a match of re_str merely at the beginning of the string. But anyway, match() is the solution to our question, as we can see in the following example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAdJo8edqNfo",
        "outputId": "88665900-9310-4ea5-e711-b3898d1db40d"
      },
      "source": [
        "import re\n",
        "s1 = \"Mayer is a very common Name\"\n",
        "s2 = \"He is called Meyer but he isn't German.\"\n",
        "print(re.search(r\"M[ae][iy]er\", s1))\n",
        "print(re.search(r\"M[ae][iy]er\", s2))\n",
        " # matches because it starts with Mayer\n",
        "print(re.match(r\"M[ae][iy]er\", s1)) \n",
        "# doesn't match because it doesn't start with Meyer or Meyer, Meier and so on:\n",
        "print(re.match(r\"M[ae][iy]er\", s2))  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 5), match='Mayer'>\n",
            "<re.Match object; span=(13, 18), match='Meyer'>\n",
            "<re.Match object; span=(0, 5), match='Mayer'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7fnGDYlu-aC"
      },
      "source": [
        "So, this is a way to match the start of a string, but it's a Python specific method, i.e. it can't be used in other languages like Perl, AWK and so on. There is a general solution which is a standard for regular expressions:\n",
        "\n",
        "The caret '^' matches the start of the string, and in MULTILINE (will be explained further down) mode also matches immediately after each newline, which the Python method match() doesn't do. The caret has to be the first character of a regular expression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo8dDR47vBox",
        "outputId": "4128e45e-8835-41ea-fc05-d8c7e3950ac7"
      },
      "source": [
        "import re\n",
        "s1 = \"Mayer is a very common Name\"\n",
        "s2 = \"He is called Meyer but he isn't German.\"\n",
        "print(re.search(r\"^M[ae][iy]er\", s1))\n",
        "print(re.search(r\"^M[ae][iy]er\", s2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 5), match='Mayer'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bAHJwJKvyTK"
      },
      "source": [
        "But what happens if we concatenate the two strings s1 and s2 in the following way?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdO_zGevDeW"
      },
      "source": [
        "s = s2 + \"\\n\" + s1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9I0czNnv5Ec"
      },
      "source": [
        "Now the string doesn't start with a Maier of any kind, but the name follows a newline character:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPEhG1aNv3Uo",
        "outputId": "13fe6aa4-e936-4a58-9689-0399cb8d5ab3"
      },
      "source": [
        "s = s2 + \"\\n\" + s1\n",
        "print(re.search(r\"^M[ae][iy]er\", s))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSyxSlOBv9dM"
      },
      "source": [
        "The name hasn't been found, because only the beginning of the string is checked. It changes, if we use the multiline mode, which can be activated by adding the following parameters to search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXZ0fOE_v7AR",
        "outputId": "2f91fdea-174f-423e-c2f7-2e0083e749ee"
      },
      "source": [
        "print(re.search(r\"^M[ae][iy]er\", s, re.MULTILINE))\n",
        "print(re.search(r\"^M[ae][iy]er\", s, re.M))\n",
        "print(re.match(r\"^M[ae][iy]er\", s, re.M))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(40, 45), match='Mayer'>\n",
            "<re.Match object; span=(40, 45), match='Mayer'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ss3H4awFGp"
      },
      "source": [
        "The previous example also shows that the multiline mode doesn't affect the match method. match() never checks anything but the beginning of the string for a match.\n",
        "\n",
        "We have learnt how to match the beginning of a string. What about the end? Of course that's possible to. The dollar sign matches the end of a string or just before the newline at the end of the string. If in MULTILINE mode, it also matches before a newline. We demonstrate the usage of the \"$\" character in the following example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU8D9Rjiv_5B",
        "outputId": "ea851cd7-5da1-4b4c-98a1-cb995188e149"
      },
      "source": [
        "print(re.search(r\"Python\\.$\",\"I like Python.\"))\n",
        "print(re.search(r\"Python\\.$\",\"I like Python and Perl.\"))\n",
        "print(re.search(r\"Python\\.$\",\"I like Python.\\nSome prefer Java or Perl.\"))\n",
        "print(re.search(r\"Python\\.$\",\"I like Python.\\nSome prefer Java or Perl.\", re.M))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(7, 14), match='Python.'>\n",
            "None\n",
            "None\n",
            "<re.Match object; span=(7, 14), match='Python.'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpX8Ytj2weSQ"
      },
      "source": [
        "#### Optional items\n",
        "\n",
        "If you thought that our collection of Mayer names was complete, you were wrong. There are other ones all over the world, e.g. London and Paris, who dropped their \"e\". So we have four more names [\"Mayr\", \"Meyr\", \"Meir\", \"Mair\"] plus our old set [\"Mayer\", \"Meyer\", \"Meier\", \"Maier\"].\n",
        "\n",
        "If we try to figure out a fitting regular expression, we realize that we miss something. A way to tell the computer \"this \"e\" may or may not occur\". A question mark is used as a notation for this. A question mark declares that the preceding character or expression is optional.\n",
        "\n",
        "The final Mayer-Recognizer looks now like this:\n",
        "\n",
        "```r\"M[ae][iy]e?r\"```\n",
        "\n",
        "A subexpression is grouped by round brackets and a question mark following such a group means that this group may or may not exist. With the following expression we can match dates like \"Feb 2011\" or February 2011\":\n",
        "\n",
        "```r\"Feb(ruary)? 2011\"```\n",
        "\n",
        "#### Quantifiers\n",
        "\n",
        "If you just use what we have introduced so far, you will still need a lot of things, above all some way of repeating characters or regular expressions. For this purpose, quantifiers are used. We have encountered one in the previous paragraph, i.e. the question mark.\n",
        "\n",
        "A quantifier after a token, which can be a single character or group in brackets, specifies how often that preceding element is allowed to occur. The most common quantifiers are:\n",
        "\n",
        "* the question mark ?\n",
        "* the asterisk or star character * ~~(which is derived from the Kleene star)~~\n",
        "* and the plus sign + ~~(derived from the Kleene cross)~~\n",
        "\n",
        "We have already previously used one of these quantifiers without explaining it, i.e. the asterisk. A star following a character or a subexpression group means that this expression or character may be repeated arbitrarily, even zero times.\n",
        "\n",
        "```r\"[0-9]*\"```\n",
        "\n",
        "The above expression matches any sequence of digits, even the empty string. ```r\".*\"``` matches any sequence of characters and the empty string.\n",
        "\n",
        "**Exercise:** Write a regular expression which matches strings which starts with a sequence of digits - at least one digit - followed by a blank.\n",
        "\n",
        "**Solution:**\n",
        "\n",
        "```r\"^[0-9][0-9]* \"```\n",
        "\n",
        "The plus operator is very convenient to solve the previous exercise. The plus operator is very similar to the star operator, except that the character or subexpression followed by a \"+\" sign has to be repeated at least one time. Here follows the solution to our exercise with the plus quantifier\n",
        "\n",
        "**Solution with the plus quantifier:**\n",
        "\n",
        "```r\"^[0-9]+ \"```\n",
        "\n",
        "If you work with this arsenal of operators for a while, you will inevitably miss the possibility to repeat expressions for an exact number of times at some point. Let's assume you want to recognize the last lines of addresses on envelopes in Switzerland. These lines usually contain a four digits long post code followed by a blank and a city name. Let's assume that there is no city name in Switzerland, which consists of less than 3 letters, at least 3 letters. We can denote this by [A-Za-z]{3,}. Now we have to recognize lines with German post code (5 digits) lines as well, i.e. the post code can now consist of either four or five digits:\n",
        "\n",
        "```r\"^[0-9]{4,5} [A-Z][a-z]{2,}\"```\n",
        "\n",
        "The general syntax is {from, to}, meaning the expression has to appear at least \"from\" times and not more than \"to\" times. {, to} is an abbreviated spelling for {0,to} and {from,} is an abbreviation for \"at least from times but no upper limit\"\n",
        "\n",
        "#### Grouping\n",
        "\n",
        "We can group a part of a regular expression by surrounding it with parenthesis (round brackets). This way we can apply operators to the complete group instead of a single character.\n",
        "\n",
        "#### Capturing Groups and Back References\n",
        "\n",
        "Parenthesis (round brackets, braces) are not only group subexpressions but they also create back references. The part of the string matched by the grouped part of the regular expression, i.e. the subexpression in parenthesis, is stored in a back reference. With the aid of back references we can reuse parts of regular expressions. These stored values can be both reused inside the expression itself and afterwards, when the regexpr is executed. Before we continue with our treatise about back references, we want to strew in a paragraph about match objects, which is important for our next examples with back references.\n",
        "\n",
        "#### A Closer Look at the Match Objects\n",
        "\n",
        "So far we have just checked, if an expression matched or not. We used the fact the re.search() returns a match object if it matches and None otherwise. We haven't been interested e.g. in what has been matched. The match object contains a lot of data about what has been matched, positions and so on.\n",
        "\n",
        "A match object contains the methods group(), span(), start() and end(), as it can be seen in the following application:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "epPA9EqtwceK",
        "outputId": "bd3189f8-13ef-4ca9-db8b-da8a586b9a2d"
      },
      "source": [
        "import re\n",
        "mo = re.search(\"[0-9]+\", \"Customer number: 232454, Date: February 12, 2011\")\n",
        "mo.group()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'232454'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfuPbjE-0pQ7",
        "outputId": "b296ed4b-3b33-4dce-81fe-39a5c8d1c2d5"
      },
      "source": [
        "mo.span()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csvb124Y0vr9",
        "outputId": "3b7a6019-2756-4f04-a41e-a60a2e358d7e"
      },
      "source": [
        "mo.start()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an0o-R3K0xpM",
        "outputId": "69f11240-9b71-4039-aa86-c693789631aa"
      },
      "source": [
        "mo.end()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119Jnyyc1d8y"
      },
      "source": [
        "These methods are not difficult to understand. span() returns a tuple with the start and end position, i.e. the string index where the regular expression started matching in the string and ended matching. The methods start() and end() are in a way superfluous as the information is contained in span(), i.e. span()[0] is equal to start() and span()[1] is equal to end(). group(), if called without argument, it returns the substring, which had been matched by the complete regular expression. With the help of group() we are also capable of accessing the matched substring by grouping parentheses, to get the matched substring of the n-th group, we call group() with the argument n: group(n). We can also call group with more than integer argument, e.g. group(n,m). group(n,m) - provided there exists a subgoup n and m - returns a tuple with the matched substrings. group(n,m) is equal to (group(n), group(m)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "08Uiymf_06cg",
        "outputId": "388f4923-2e5e-464d-c38a-170125b49628"
      },
      "source": [
        "import re\n",
        "mo = re.search(\"([0-9]+).*: (.*)\", \"Customer number: 232454, Date: February 12, 2011\")\n",
        "mo.group()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'232454, Date: February 12, 2011'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "SpKWHw9b1g77",
        "outputId": "f99e3a6d-5cde-4db1-ae92-560f1480b0d2"
      },
      "source": [
        "mo.group(1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'232454'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "CtoCiVWM4I3h",
        "outputId": "56256895-cc9b-424d-cb96-99e4e937fcb9"
      },
      "source": [
        "mo.group(2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'February 12, 2011'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjPWGAF04MCo",
        "outputId": "6243c18f-6888-4f82-f082-455971e60ce1"
      },
      "source": [
        "mo.group(2, 1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('February 12, 2011', '232454')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXwt-zZT4gAn"
      },
      "source": [
        "A very intuitive example are XML or HTML tags. E.g. let's assume we have a file (called \"tags.txt\") with content like this:\n",
        "\n",
        "```\n",
        "<composer> Wolfgang Amadeus Mozart </composer>\n",
        "<author> Samuel Beckett </author>\n",
        "<city> London </city>\n",
        "```\n",
        "\n",
        "We want to rewrite this text automatically to\n",
        "\n",
        "```\n",
        "composer: Wolfgang Amadeus Mozart\n",
        "author: Samuel Beckett\n",
        "city: London\n",
        "```\n",
        "\n",
        "The following little Python script does the trick. The core of this script is the regular expression. This regular expression works like this: It tries to match a less than symbol \"<\". After this it is reading lower case letters until it reaches the greater than symbol. Everything encountered within \"<\" and \">\" has been stored in a back reference which can be accessed within the expression by writing \\1. Let's assume \\1 contains the value \"composer\". When the expression has reached the first \">\", it continues matching, as the original expression had been \"(.*)\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3WabLLp4OlT",
        "outputId": "76b69fc1-44c3-4581-bce3-80b1939a2268"
      },
      "source": [
        "text = '''<composer> Wolfgang Amadeus Mozart </composer>\n",
        "          <author> Samuel Beckett </author>\n",
        "          <city> London </city>\n",
        "       '''\n",
        "\n",
        "with open('tags.txt', 'w') as h:\n",
        "    print(text, file=h)\n",
        "\n",
        "!cat tags.txt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<composer> Wolfgang Amadeus Mozart </composer>\n",
            "          <author> Samuel Beckett </author>\n",
            "          <city> London </city>\n",
            "       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgmtPGuH4-a8",
        "outputId": "fdea3eeb-779f-4605-d220-1471da48410e"
      },
      "source": [
        "import re\n",
        "fh = open(\"tags.txt\")\n",
        "for i in fh:\n",
        "     i = i.strip()\n",
        "     if i:\n",
        "        res = re.search(r\"<([a-z]+)>(.*)</\\1>\",i)\n",
        "        print(res.group(1) + \": \" + res.group(2))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "composer:  Wolfgang Amadeus Mozart \n",
            "author:  Samuel Beckett \n",
            "city:  London \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw2fp6YJ6NR1"
      },
      "source": [
        "If there are more than one pair of parenthesis (round brackets) inside the expression, the backreferences are numbered \\1, \\2, \\3, in the order of the pairs of parenthesis.\n",
        "\n",
        "**Exercise:** The next Python example makes use of three back references. We have an imaginary phone list of the Simpsons in a list. Not all entries contain a phone number, but if a phone number exists it is the first part of an entry. Then, separated by a blank, a surname follows, which is followed by first names. Surname and first name are separated by a comma. The task is to rewrite this example in the following way:\n",
        "\n",
        "```\n",
        "Allison Neu 555-8396\n",
        "C. Montgomery Burns \n",
        "Lionel Putz 555-5299\n",
        "Homer Jay Simpson 555-73347\n",
        "```\n",
        "\n",
        "Python script solving the rearrangement problem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS8pNdBC4_0r",
        "outputId": "b323fbdb-21de-4a3b-a233-06ec19cb11a5"
      },
      "source": [
        "import re\n",
        "\n",
        "l = [\"555-8396 Neu, Allison\", \n",
        "     \"Burns, C. Montgomery\", \n",
        "     \"555-5299 Putz, Lionel\",\n",
        "     \"555-7334 Simpson, Homer Jay\"]\n",
        "\n",
        "for i in l:\n",
        "    res = re.search(r\"([0-9-]*)\\s*([A-Za-z]+),\\s+(.*)\", i)\n",
        "    print(res.group(3) + \" \" + res.group(2) + \" \" + res.group(1))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allison Neu 555-8396\n",
            "C. Montgomery Burns \n",
            "Lionel Putz 555-5299\n",
            "Homer Jay Simpson 555-7334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL2pV3P86oF1"
      },
      "source": [
        "#### Named Backreferences\n",
        "\n",
        "In the previous paragraph we introduced \"Capturing Groups\" and \"Back references\". More precisely, we could have called them \"Numbered Capturing Groups\" and \"Numbered Backreferences\". Using capturing groups instead of \"numbered\" capturing groups allows you to assign descriptive names instead of automatic numbers to the groups. In the following example, we demonstrate this approach by catching the hours, minutes and seconds from a UNIX date string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Gf5ElryE6laP",
        "outputId": "dcc71290-30cf-4ccf-e923-dd50a7192328"
      },
      "source": [
        "import re\n",
        "s = \"Sun Oct 14 13:47:03 CEST 2012\"\n",
        "expr = r\"\\b(?P<hours>\\d\\d):(?P<minutes>\\d\\d):(?P<seconds>\\d\\d)\\b\"\n",
        "x = re.search(expr,s)\n",
        "x.group('hours')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'13'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-2_cgjs6w_T",
        "outputId": "5392c522-8189-4496-e927-ba28dce38d8e"
      },
      "source": [
        "x.span('seconds')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0w_4Hf9As-o"
      },
      "source": [
        "#### [What is a non-capturing group in regular expressions?](https://stackoverflow.com/questions/3512471/what-is-a-non-capturing-group-in-regular-expressions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbBDkxMr7XJ5"
      },
      "source": [
        "## Advanced Regular Expressions\n",
        "\n",
        "#### Finding all Matched Substrings\n",
        "\n",
        "The Python module re provides another great method, which other languages like Perl and Java don't provide. If you want to find all the substrings in a string, which match a regular expression, you have to use a loop in Perl and other languages, as can be seen in the following Perl snippet:\n",
        "\n",
        "```perl\n",
        "while ($string =~ m/regex/g) {\n",
        "  print \"Found '$&'.  Next attempt at character \" . pos($string)+1 . \"\\n\";\n",
        "}\n",
        "```\n",
        "\n",
        "It's a lot easier in Python. No need to loop. We can just use the findall method of the re module:\n",
        "\n",
        "```re.findall(pattern, string[, flags])```\n",
        "\n",
        "Findall returns all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order in which they are found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmjFj9D7RFH",
        "outputId": "a124ad69-bb9f-4d1b-93d9-54f960466295"
      },
      "source": [
        "t=\"A fat cat doesn't eat oat but a rat eats bats.\"\n",
        "mo = re.findall(\"[force]at\", t)\n",
        "print(mo)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fat', 'cat', 'eat', 'oat', 'rat', 'eat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo-J5FDU9U-s"
      },
      "source": [
        "If one or more groups are present in the pattern, findall returns a list of groups. This will be a list of tuples if the pattern has more than one group. We demonstrate this in our next example. We have a long string with various Python training courses and their dates. With the first call to findall, we don't use any grouping and receive the complete string as a result. In the next call, we use grouping and findall returns a list of 2-tuples, each having the course name as the first component and the dates as the second component:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjLiZ-T81GW",
        "outputId": "7cebbe03-db15-451c-b67f-30b08895b579"
      },
      "source": [
        "import re\n",
        "courses = \"Python Training Course for Beginners: 15/Aug/2011 - 19/Aug/2011;Python Training Course Intermediate: 12/Dec/2011 - 16/Dec/2011;Python Text Processing Course:31/Oct/2011 - 4/Nov/2011\"\n",
        "items = re.findall(\"[^:]*:[^;]*;?\", courses)\n",
        "items"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python Training Course for Beginners: 15/Aug/2011 - 19/Aug/2011;',\n",
              " 'Python Training Course Intermediate: 12/Dec/2011 - 16/Dec/2011;',\n",
              " 'Python Text Processing Course:31/Oct/2011 - 4/Nov/2011']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alyQ6ygM9W59",
        "outputId": "1aa67ffa-7e38-4d91-9f2e-3ce8e65a4e6e"
      },
      "source": [
        "items = re.findall(\"([^:]*):([^;]*;?)\", courses)\n",
        "items"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Python Training Course for Beginners', ' 15/Aug/2011 - 19/Aug/2011;'),\n",
              " ('Python Training Course Intermediate', ' 12/Dec/2011 - 16/Dec/2011;'),\n",
              " ('Python Text Processing Course', '31/Oct/2011 - 4/Nov/2011')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugAiXsBP9q0A"
      },
      "source": [
        "#### Alternations\n",
        "\n",
        "In our introduction to regular expressions we had introduced character classes. Character classes offer a choice out of a set of characters. Sometimes we need a choice between several regular expressions. It's a logical \"or\" and that's why the symbol for this construct is the \"|\" symbol. In the following example, we check, if one of the cities London, Paris, Zurich, Konstanz Bern or Strasbourg appear in a string preceded by the word \"location\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb0aDk9B9ZU4",
        "outputId": "a419899b-e216-4fbe-d0fc-b703fed2165f"
      },
      "source": [
        "# greedy:\n",
        "\n",
        "import re\n",
        "str = \"Course location is London or Paris!\"\n",
        "mo = re.search(r\"location.*(London|Paris|Zurich|Strasbourg)\", str)\n",
        "if mo: print(mo.group())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "location is London or Paris\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-qC64gABE6u"
      },
      "source": [
        "#### Compiling Regular Expressions\n",
        "\n",
        "If you want to use the same regexp more than once in a script, it might be a good idea to use a regular expression object, i.e. the regex is compiled.\n",
        "\n",
        "The general syntax:\n",
        "\n",
        "```re.compile(pattern[, flags])```\n",
        "\n",
        "compile returns a regex object, which can be used later for searching and replacing. The expressions behaviour can be modified by specifying a flag value:\n",
        "\n",
        "|Abbreviation| Full name  |\n",
        "|----------- | -----------|\n",
        "| re.I   | re.IGNORECASE   |\n",
        "| re.L   | re.LOCALE       |\n",
        "| re.M   | re.MULTILINE    |\n",
        "| re.S   | re.DOTALL       |\n",
        "| re.U   | re.UNICODE      |\n",
        "| re.X   | re.VERBOSE      |\n",
        "\n",
        "Compiled regular objects usually are not saving much time, because Python internally compiles AND CACHES regexes whenever you use them with re.search() or re.match(). The only extra time a non-compiled regex takes is the time it needs to check the cache, which is a key lookup of a dictionary.\n",
        "\n",
        "A good reason to use them is to separate the definition of a regex from its use.\n",
        "\n",
        "#### Splitting a String With or Without Regular Expressions\n",
        "\n",
        "There is a string method split, which can be used to split a string into a list of substrings:\n",
        "\n",
        "``` str.split([sep[, maxsplit]])```\n",
        "\n",
        "As you can see, the method split has two optional parameters. If none is given (or is None) , a string will be separated into substring using whitespaces as delimiters, i.e. every substring consisting purely of whitespaces is used as a delimiter.\n",
        "\n",
        "![](https://www.python-course.eu/images/re_split.webp)\n",
        "\n",
        "We demonstrate this behaviour with a famous quotation by Abraham Lincoln:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx9abbum-OIg",
        "outputId": "c7904b8c-f287-431e-d72a-1e5892e325d4"
      },
      "source": [
        "law_courses = \"Let reverence for the laws be breathed by every American mother to the lisping babe that prattles on her lap. Let it be taught in schools, in seminaries, and in colleges. Let it be written in primers, spelling books, and in almanacs. Let it be preached from the pulpit, proclaimed in legislative halls, and enforced in the courts of justice. And, in short, let it become the political religion of the nation.\"\n",
        "law_courses.split()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Let',\n",
              " 'reverence',\n",
              " 'for',\n",
              " 'the',\n",
              " 'laws',\n",
              " 'be',\n",
              " 'breathed',\n",
              " 'by',\n",
              " 'every',\n",
              " 'American',\n",
              " 'mother',\n",
              " 'to',\n",
              " 'the',\n",
              " 'lisping',\n",
              " 'babe',\n",
              " 'that',\n",
              " 'prattles',\n",
              " 'on',\n",
              " 'her',\n",
              " 'lap.',\n",
              " 'Let',\n",
              " 'it',\n",
              " 'be',\n",
              " 'taught',\n",
              " 'in',\n",
              " 'schools,',\n",
              " 'in',\n",
              " 'seminaries,',\n",
              " 'and',\n",
              " 'in',\n",
              " 'colleges.',\n",
              " 'Let',\n",
              " 'it',\n",
              " 'be',\n",
              " 'written',\n",
              " 'in',\n",
              " 'primers,',\n",
              " 'spelling',\n",
              " 'books,',\n",
              " 'and',\n",
              " 'in',\n",
              " 'almanacs.',\n",
              " 'Let',\n",
              " 'it',\n",
              " 'be',\n",
              " 'preached',\n",
              " 'from',\n",
              " 'the',\n",
              " 'pulpit,',\n",
              " 'proclaimed',\n",
              " 'in',\n",
              " 'legislative',\n",
              " 'halls,',\n",
              " 'and',\n",
              " 'enforced',\n",
              " 'in',\n",
              " 'the',\n",
              " 'courts',\n",
              " 'of',\n",
              " 'justice.',\n",
              " 'And,',\n",
              " 'in',\n",
              " 'short,',\n",
              " 'let',\n",
              " 'it',\n",
              " 'become',\n",
              " 'the',\n",
              " 'political',\n",
              " 'religion',\n",
              " 'of',\n",
              " 'the',\n",
              " 'nation.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjOlb25EDa5v"
      },
      "source": [
        "Now we look at a string, which could stem from an Excel or an OpenOffice calc file. We have seen in our previous example that split takes whitespaces as default separators. We want to split the string in the following little example using semicolons as separators. The only thing we have to do is to use \";\" as an argument of split():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_oKZMcQDHaX",
        "outputId": "7553e3e9-7ffd-49fe-8662-74134f748c1c"
      },
      "source": [
        "line = \"James;Miller;teacher;Perl\"\n",
        "line.split(\";\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['James', 'Miller', 'teacher', 'Perl']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFK-OQdDihx"
      },
      "source": [
        "The method split() has another optional parameter: maxsplit. If maxsplit is given, at most maxsplit splits are done. This means that the resulting list will have at most \"maxsplit + 1\" elements. We will illustrate the mode of operation of maxsplit in the next example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqFzU0d5Dc7P",
        "outputId": "e5e38ca8-ee7e-4216-c75f-c8588a22586c"
      },
      "source": [
        "mammon = \"The god of the world's leading religion. The chief temple is in the holy city of New York.\"\n",
        "mammon.split(\" \",3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'god',\n",
              " 'of',\n",
              " \"the world's leading religion. The chief temple is in the holy city of New York.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPHgU5gjDqwb"
      },
      "source": [
        "We used a Blank as a delimiter string in the previous example, which can be a problem: If multiple blanks or whitespaces are connected, split() will split the string after every single blank, so that we will get empty strings and strings with only a tab inside ('\\t') in our result list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-y8ZGy5DkfL",
        "outputId": "1e74c135-269b-4015-c6ed-b0249e724339"
      },
      "source": [
        "mammon = \"The god  \\t of the world's leading religion. The chief temple is in the holy city of New York.\"\n",
        "mammon.split(\" \",5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'god',\n",
              " '',\n",
              " '\\t',\n",
              " 'of',\n",
              " \"the world's leading religion. The chief temple is in the holy city of New York.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksQY6uKzD9LS"
      },
      "source": [
        "We can prevent the separation of empty strings by using None as the first argument. Now split will use the default behaviour, i.e. every substring consisting of connected whitespace characters will be taken as one separator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GeKhddDDyjb",
        "outputId": "0ad3c905-b05a-437d-f1af-18d410b662b3"
      },
      "source": [
        "mammon.split(None,5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'god',\n",
              " 'of',\n",
              " 'the',\n",
              " \"world's\",\n",
              " 'leading religion. The chief temple is in the holy city of New York.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-R8av8gEKfD"
      },
      "source": [
        "#### Regular Expression Split\n",
        "\n",
        "The string method split() is the right tool in many cases, but what, if you want e.g. to get the bare words of a text, i.e. without any special characters and whitespaces. If we want this, we have to use the split function from the re module. We illustrate this method with a short text from the beginning of Metamorphoses by Ovid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKitEEcREIQL",
        "outputId": "05e54512-c90b-4a65-b8ef-726cccdad81d"
      },
      "source": [
        "import re\n",
        "metamorphoses = \"OF bodies chang'd to various forms, I sing: Ye Gods, from whom these miracles did spring, Inspire my numbers with coelestial heat;\"\n",
        "re.split(\"\\W+\", metamorphoses)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OF',\n",
              " 'bodies',\n",
              " 'chang',\n",
              " 'd',\n",
              " 'to',\n",
              " 'various',\n",
              " 'forms',\n",
              " 'I',\n",
              " 'sing',\n",
              " 'Ye',\n",
              " 'Gods',\n",
              " 'from',\n",
              " 'whom',\n",
              " 'these',\n",
              " 'miracles',\n",
              " 'did',\n",
              " 'spring',\n",
              " 'Inspire',\n",
              " 'my',\n",
              " 'numbers',\n",
              " 'with',\n",
              " 'coelestial',\n",
              " 'heat',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axXupIvFEiG-"
      },
      "source": [
        "The following example is a good case, where the regular expression is really superior to the string split. Let's assume that we have data lines with surnames, first names and professions of names. We want to clear the data line of the superfluous and redundant text descriptions, i.e. \"surname: \", \"prename: \" and so on, so that we have solely the surname in the first column, the first name in the second column and the profession in the third column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBXayxTtEZOV",
        "outputId": "9413be21-7828-4609-8be8-cd2a683c1843"
      },
      "source": [
        "import re\n",
        "lines = [\"surname: Obama, prename: Barack, profession: president\", \"surname: Merkel, prename: Angela, profession: chancellor\"]\n",
        "for line in lines:\n",
        "    print(re.split(\",* *\\w*: \", line))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'Obama', 'Barack', 'president']\n",
            "['', 'Merkel', 'Angela', 'chancellor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-LnRBN8E2j7"
      },
      "source": [
        "We can easily improve the script by using a slice operator, so that we don't have the empty string as the first element of our result lists:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkmsfFV9E2Eq",
        "outputId": "c0681369-44c8-4e56-f761-5ad0e37a0fb0"
      },
      "source": [
        "import re\n",
        "lines = [\"surname: Obama, prename: Barack, profession: president\", \"surname: Merkel, prename: Angela, profession: chancellor\"]\n",
        "for line in lines:\n",
        "    print(re.split(\",* *\\w*: \", line)[1:])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Obama', 'Barack', 'president']\n",
            "['Merkel', 'Angela', 'chancellor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7tVohopE-fb"
      },
      "source": [
        "#### Search and Replace with sub\n",
        "\n",
        "```re.sub(regex, replacement, subject)```\n",
        "\n",
        "Every match of the regular expression regex in the string subject will be replaced by the string replacement. Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMXXwUu0EjxE",
        "outputId": "1ff0df1d-c014-4068-c432-559c531d2d05"
      },
      "source": [
        "import re\n",
        "str = \"yes I said yes I will Yes.\"\n",
        "res = re.sub(\"[yY]es\",\"no\", str)\n",
        "print(res)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no I said no I will no.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h1Jm1PkFKub"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}